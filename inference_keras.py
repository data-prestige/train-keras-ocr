# -*- coding: utf-8 -*-
"""Keras-OCR Experiment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TVDgM_xw_QH655ZJe0DQlUxnI33-KHjD
"""

import glob, os
from pathlib import Path
import tensorflow as tf
import matplotlib.pyplot as plt
from vocabolary import LabelConverter

import keras_ocr
label_converter = LabelConverter()

"""## Data loading (tf.data)"""

# Find all the images inside the folder (only the name)

data_dir = Path("../validation/")
validation_lp = Path("../validation/")

# Split into folder and name
_, paths, images = zip(*[p.parts for p in data_dir.glob("*.jpg")])
paths, images = list(paths), list(images)
_, val_paths, val_images = zip(*[p.parts for p in validation_lp.glob("*.jpg")])
val_paths, val_images = list(val_paths), list(val_images)

img_width = 200
img_height = 31
batch_size = 8

# Load inside a TF dataset
dataset = tf.data.Dataset.from_tensor_slices((paths, images))
val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_images))

print(f'There are {len(dataset)} training images.')
print(f'There are {len(val_dataset)} validation images.')

def process_path(image_path, image_name):
    # Convert the dataset as:
    # (path, filename) --> (image, label [str])

    # Load the image and resize
    img = tf.io.read_file(".."+ os.sep +image_path + os.sep + image_name)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, [img_height, img_width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
    # img = tf.cast(img[:, :, :], tf.int8)

    # Get the label and its length
    label = tf.strings.split(image_name, '.jpg')[0]
    label = tf.strings.split(label, '_')[0]
    label = tf.strings.split(label, ' ')[0]
    label = tf.strings.upper(label)

    return img, label

# Apply the preprocessing to each image
dataset = dataset.map(process_path)
val_dataset = val_dataset.map(process_path)

for xb, yb in dataset:
    plt.imshow(xb.numpy())
    print(yb)
    break

"""## Build the lookup dictionary"""

# Now we build the dictionary of characters.
# I am assuming every character we have is valid, but this can be changed accordingly.


# Check the vocabulary
print(label_converter.lookup.get_vocabulary())

"""## Build and train the keras-ocr recognizer"""

# Overwrite default width and height.
# Note: if you use the default ones, we might be able to use the pretrained weights.
build_params = keras_ocr.recognition.DEFAULT_BUILD_PARAMS 
build_params['width'] = img_width
build_params['height'] = img_height

# Version with custom vocabulary
recognizer = keras_ocr.recognition.Recognizer(alphabet=label_converter.lookup.get_vocabulary(), weights=None, build_params=build_params)
recognizer.prediction_model.load_weights("recognizer_borndigital.h5")
print(recognizer.alphabet)

def val_gen():
  for xb, yb in val_dataset.repeat():
    yield xb.numpy(), str(yb.numpy(), 'utf-8')

# For models 1-2, remove lowercase
val_data_gen = recognizer.get_batch_generator(val_gen(), batch_size=batch_size, lowercase=True)

# xb, yb are basically the same as our code... Maybe we can reuse that part of the code?
# These generators are more or less equivalent to those we build in our notebook.
validation_steps = len(val_dataset) // batch_size

print(validation_steps)

recognizer.compile()

for xb, yb in dataset:
  plt.figure()
  plt.imshow(xb.numpy())
  print(recognizer.recognize(xb.numpy()))

recognizer.recognize(xb.numpy())