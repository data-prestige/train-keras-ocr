# -*- coding: utf-8 -*-
"""Keras-OCR Experiment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TVDgM_xw_QH655ZJe0DQlUxnI33-KHjD
"""

import glob, os
from pathlib import Path
import tensorflow as tf
import matplotlib.pyplot as plt

import keras_ocr

"""## Data loading (tf.data)"""

# Find all the images inside the folder (only the name)

data_dir = Path("../images/")
validation_lp = Path("../images/")

# Split into folder and name
_, paths, images = zip(*[p.parts for p in data_dir.glob("*.jpg")])
paths, images = list(paths), list(images)
_, val_paths, val_images = zip(*[p.parts for p in validation_lp.glob("*.jpg")])
val_paths, val_images = list(val_paths), list(val_images)

img_width = 200
img_height = 31
batch_size = 8

# Load inside a TF dataset
dataset = tf.data.Dataset.from_tensor_slices((paths, images))
val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_images))

print(f'There are {len(dataset)} training images.')
print(f'There are {len(val_dataset)} validation images.')

def process_path(image_path, image_name):
    # Convert the dataset as:
    # (path, filename) --> (image, label [str])

    # Load the image and resize
    img = tf.io.read_file(".."+ os.sep +image_path + os.sep + image_name)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, [img_height, img_width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
    # img = tf.cast(img[:, :, :], tf.int8)

    # Get the label and its length
    label = tf.strings.split(image_name, '.jpg')[0]
    label = tf.strings.split(label, '_')[0]
    label = tf.strings.split(label, ' ')[0]
    label = tf.strings.upper(label)

    return img, label

# Apply the preprocessing to each image
dataset = dataset.map(process_path)
val_dataset = val_dataset.map(process_path)

for xb, yb in dataset:
    plt.imshow(xb.numpy())
    print(yb)
    break

"""## Build the lookup dictionary"""

# Now we build the dictionary of characters.
# I am assuming every character we have is valid, but this can be changed accordingly.
lookup = tf.keras.layers.experimental.preprocessing.StringLookup(
    num_oov_indices=0, mask_token=None,
)
lookup.adapt(dataset.map(lambda _, yb: tf.strings.bytes_split(yb)))

# Check the vocabulary
print(lookup.get_vocabulary())

"""## Build and train the keras-ocr recognizer"""

# Overwrite default width and height.
# Note: if you use the default ones, we might be able to use the pretrained weights.
build_params = keras_ocr.recognition.DEFAULT_BUILD_PARAMS 
build_params['width'] = img_width
build_params['height'] = img_height

# Version with custom vocabulary
recognizer = keras_ocr.recognition.Recognizer(alphabet=lookup.get_vocabulary(), weights=None,
                                             build_params=build_params)

# Version with custom vocabulary and pretrained weights
recognizer = keras_ocr.recognition.Recognizer(alphabet=lookup.get_vocabulary())

# Check variables are not freezed
# for p in recognizer.training_model.variables:
#   print(p.trainable)

# Version with fully pre-trained weigths and original vocabulary
recognizer = keras_ocr.recognition.Recognizer()

print(recognizer.alphabet)

# This is a terrible hack because we are going back to NumPy only to move back to TensorFlow :-(
def train_gen():
  for xb, yb in dataset.repeat():
    yield xb.numpy(), str(yb.numpy(), 'utf-8')

def val_gen():
  for xb, yb in val_dataset.repeat():
    yield xb.numpy(), str(yb.numpy(), 'utf-8')

# For models 1-2, remove lowercase
train_data_gen = recognizer.get_batch_generator(train_gen(), batch_size=batch_size, lowercase=True)
val_data_gen = recognizer.get_batch_generator(val_gen(), batch_size=batch_size, lowercase=True)


# xb, yb are basically the same as our code... Maybe we can reuse that part of the code?
# These generators are more or less equivalent to those we build in our notebook.
training_steps = len(dataset) // batch_size
validation_steps = len(val_dataset) // batch_size

print(training_steps)
print(validation_steps)

recognizer.compile()

callbacks = [
    tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, restore_best_weights=False),
    tf.keras.callbacks.ModelCheckpoint('recognizer_borndigital.h5', monitor='val_loss', save_best_only=True),
    tf.keras.callbacks.CSVLogger('recognizer_borndigital.csv')
]
recognizer.training_model.fit_generator(
    generator=train_data_gen,
    steps_per_epoch=training_steps,
    validation_steps=validation_steps,
    validation_data=val_data_gen,
    callbacks=callbacks,
    epochs=1000,
)

for xb, yb in dataset:
  plt.figure()
  plt.imshow(xb.numpy())
  print(recognizer.recognize(xb.numpy()))

recognizer.recognize(xb.numpy())

